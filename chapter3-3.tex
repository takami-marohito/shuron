\section{提案手法のアルゴリズム}
先に述べた計算手法を計算機上で実現するアルゴリズムについて説明する．
式\ref{eq:3-2}において，求めたい係数行列$\theta$は$n \times 1$行列で，nは海洋環境変数の数である．
一方で$\theta$を求めるために使うことができる式の数は${\bf Y}$ の行数であり，つまり漁獲点の数である．
海洋環境変数の数は$深さインデックス \times 過去のデータのサンプリング数$で，5章で行う実験では1200種類ある．
一方の漁獲点は一ヶ月分のデータで180点程しかない．
これはつまり，1200の未知数を求めたいのに対して，式が180しかないことになる．
このような連立方程式を劣決定系という．
劣決定系の線形連立方程式の解法は様々な手法があるが，例えばどの変数をモデルに入れるかを全てのパターン試すことは今回の場合では現実的ではない．
ここでSIモデルが生物の生息環境としての適性を数値化したものであるということに立ち返ると，1200種類全ての変数がある程度以上SIモデルに影響を与えるとは考えにくい．
また，1200変数全てを用いたモデルはオーバーフィッティングの問題からも適切なモデルではない．
そこでSIモデルがスパースなモデルであると仮定する．
この仮定を置くことで圧縮センシングと呼ばれる枠組みを利用できるようになる．

解がスパースであることがわかっている劣決定系の線形連立方程式を解く枠組みとして圧縮センシングが存在する\cite{a25}．
標本化定理では信号の最大周波数成分がW以下の時，2W以上の周波数でサンプリングすると完全に再構成可能となる．
圧縮センシングでは信号がスパースであるとすることによって標本化定理で示されるサンプリング数より少ないサンプリング数で再構成ができるようになる．
このことから可逆性を保ったままデータの通信量を減らす応用やより少ない測定回数で正確に測定する応用などが研究されている．
本研究では少ないサンプリング数（実測した漁獲量）で原信号（海洋環境変数の方程式で表した漁獲量の分布）を再構成する問題なので，漁獲モデルがスパースであると仮定することで圧縮センシングの考え方を利用できる．

本研究ではその中でもIRLS（Iteratively Reweighted Least Squares）と呼ばれるアルゴリズムを利用した．
\if0
この問題のNP困難性の説明
LassoとRidgeの計算時間
\fi
\if0
この問題は劣決定系で圧縮センシングであることを説明
圧縮センシングの応用例と基本の論文
\fi

\section{IRLS}
IRLS\cite{a24}は最小二乗法を繰り返し計算することで解を得る手法である．
まず式\ref{eq:3-2}の変数を使って，行列Wを定義する．
行列Wは$m \times m$の対角行列で，mは求めようとしているSIモデルで使用する全ての海洋環境変数の数である．
そのi番目の対角成分$W_{ii} $は式\ref{eq:3-14-1}で定義する．

\begin{eqnarray}
\label{eq:3-14-1}
W_{ii} = \frac{1}{| \theta_i | + \epsilon}
\end{eqnarray}

ただし$\epsilon$は微小定数で，$\theta$の成分の内0でない任意の成分$\theta_n$に対して$\theta_n \gg \epsilon$となる定数である．
$\theta$のi番目の成分が0のときは$||W_{ii} \theta_i || = || \frac{0}{\epsilon} || = 0$となり，0でない時は$||W_{ii} \theta_i || = || \frac{\theta_i}{\theta_i} || = 1$となる．
そのため，$ ||W \theta ||^2 $はちょうどL0ノルムと同じものとなる．
式\ref{eq:3-2}はこのWを使って次のように書ける．

\begin{eqnarray}
\label{eq:3-15}
\argmin_{\theta} \left( ||{\bf Y}-{\bf X}\theta||_{2}^{2} + \lambda ||W \theta ||^2 \right) 
\end{eqnarray}

IRLS(Iteratively Reweighted Least Squares)は式\ref{eq:3-15}の$\theta$と第二項(罰則項)を交互に更新することで解に近づいていく手法である．

そのため，式\ref{eq:3-15}にステップtを導入する．
t回目の$\theta$の更新と罰則項の中のWの更新をそれぞれ$\theta^{(t)}$，$W^{(t)}$と表す．
$\theta$，Wの順に更新するものとした場合，t+1回目の$\theta$の更新は式\ref{eq:3-16}のように書ける．

\begin{eqnarray}
\label{eq:3-16}
\theta^{(t+1)} = \argmin_{\theta} \left( ||{\bf Y}-{\bf X}\theta^{(t)} ||_{2}^{2} + \lambda ||W^{(t)} \theta^{(t)} ||^2 \right) 
\end{eqnarray}

式\ref{eq:3-16}のargmin内が極値を取るとき，その$\theta$偏微分は0となる．（式\ref{eq:3-16-1}）

\begin{eqnarray}
\label{eq:3-16-1}
\frac{\partial \theta^{(t+1)}}{\partial \theta^{(t)}} = 0
\end{eqnarray}

これを満たす$\theta$が$\theta^{(t+1)}$なので式\ref{eq:3-16-1}から次式が成り立つ．

\begin{eqnarray}
\label{eq:3-16-2}
X^{T}X\theta^{(t+1)} - XY + \lambda (W^{(t)})^2 \theta^{(t+1)} = 0 \\
\label{eq:3-16-2-1}
\left( X^{T}X + \lambda (W^{(t)})^2 \right) \theta^{(t+1)} = XY 
%\\ \theta^{(t+1)} = \left( X^{T}X + \lambda (W^{(t)})^2 \right) ^{-1} XY
\end{eqnarray}

式\ref{eq:3-16-2}のWは各成分が0または1の対角行列なので$(W)^2 = W$となり，

\begin{eqnarray}
\label{eq:3-16-3}
\left( X^{T}X + \lambda W^{(t)} \right) \theta^{(t+1)} = XY
%\theta^{(t+1)} = \left( X^{T}X + \lambda W^{(t)} \right) ^{-1} XY
\end{eqnarray}

式\ref{eq:3-16-3}を$\theta$について解くことで$\theta^{(t+1)}$が計算できる．
またt+1回目のWの更新は直前に更新した$\theta^{(t+1)}$を使って式\ref{eq:3-17}のように書ける．

\begin{eqnarray}
\label{eq:3-17}
W_{ii}^{(t+1)} = \frac{1}{|\theta_{i}^{(t+1)} | + \epsilon }
\end{eqnarray}

ただし，Wは対角行列で$W_{ii}$はそのi行目i列目の成分である．

以上をまとめるとステップtを導入したWと$\theta$を使って，IRLSアルゴリズムは次のように表せる．

\begin{itemize}
\item[]{$\theta_{i}^0$ を全て1にする}
\item[]{$W_{ii}^{0}$ を全て1にする}
\item[]{while until($|| \theta^{(t+1)} - \theta^{(t)} || <tol$ ) }
\item[]{\ \ \ \ 式\ref{eq:3-16}を解くことで$\theta^{(t+1)}$を求める}
\item[]{\ \ \ \ \ \ \ \ 式\ref{eq:3-17}を解くことで$W_{ii}^{(t+1)}$を求める}
\item[]{\ \ \ \ end for}
\item[]{\ \ \ \ $W_{ii}^{(t+1)}$を統合して$W^{(t+1)}$を求める}
\item[]{\ \ \ \ t = t+1にする}
\item[]{end while}
\end{itemize}
ただし，tolは微小な定数．

\if0
なぜこのアルゴリズムが変数を減らす方向に働くのか
Wの更新としーたを求める逆行列計算を繰り返してるだけなのに
→IRLSの論文の定理5.3の条件ならIRLSは収束し，その解がk-スパースとなるらしい（6章）
\fi

\section{最適な罰則項の重みの決定}
先に説明したIRLSアルゴリズムによって，L0ノルムを罰則項としたモデル構築が可能である．
一方，モデルにはまだ罰則項の重み$\lambda$が自由度として残っている．
重み$\lambda = 0$の時は罰則項のない最小二乗法となり，重みが大きすぎると$\theta={\bf 0}$が解となる．
重みの決定については次のように行う．
重みを変化させて，それぞれの重みでモデル構築をする．
その後，各モデルについて次に説明する正答率を計算し，それが最大となる重みを選択することで重みを決定する．
このようにして決定した重みを用いて構築した漁獲モデルが，その海洋環境変数のSIモデルとなる．

\section{正答率}
本研究では正答率を定義し，その大小によって罰則項の重みを決定する．
正答率は機械学習の分類器などの評価でよく使われる指標である．
モデル構築の時に使用していないデータ，つまり未知のデータを分類させた時にどれだけ正しく判断できたのかを意味する．
本研究では次のようにして正答率を求める．
まず実測したCPUEデータ全体をテストデータと学習データに分割する．
そして学習データのみでモデル構築を行う．
テストデータの漁獲点座標を構築したモデルに入力して，CPUEの予測値を求める．
また同時に学習データ内の実測値としてのCPUEの平均値を求める．
予測したCPUEと学習データの平均CPUEを比較した時の大小を求める．
次に，予測した漁獲点での実際のCPUEと学習データの平均CPUEを比較した時の大小を求める．
これらが一致するかどうかを全てのテストデータに対し求め，その率を正答率とした．
テストデータ全体の数をN，CPUEが学習データの平均より高いかどうかの予測が当たった数をMとすると$Accuracy = M / N$となる．

\section{適合率}
本研究の実験では考察をするために適合率も求める．
適合率(Precision)とは，一方の予測をした時にそれが正しい割合である．
正の適合率(Positive Precision)であれば，CPUEが平均より多いと予測した地点の数($N^{+}$)を全体とした時の，実際のCPUEも多かった地点の数($M^{+}$)の割合($M^{+} / N^{+}$)である．
負の適合率(Negative Precision)はちょうどその逆で，CPUEが平均より少ないと予測した地点の数($N^{-}$)を全体とした時の，実際のCPUEも少なかった地点の数($M^{-}$)の割合($M^{-} / N^{-}$)である．
\if0
CPUEが学習データの平均より高いと予測した数を$N^{+}$，その中で実際のCPUEも平均より高かった数を$M^{+}$とすると，正の適合率は$Precision^{+} = M^{+} / N^{+}$となる．
CPUEが学習データの平均より低いと予測した数を$N^{-}$，その中で実際のCPUEも平均より低かった数を$M^{-}$とすると，正の適合率は$Precision^{-} = M^{-} / N^{-}$となる．
\fi

\section{再現率}
適合率だけではなく再現率も求める．
再現率(Recall)とは，一方の結果をどれだけ正しく予測できたかの割合である．
正の再現率(Positive Recall)であれば，実際のCPUEが学習データの平均より高い地点の数($L^{+}$)を全体とした中で予測したCPUEも学習データの平均より高かった地点の数($K^{+}$)の割合($K^{+}/L^{+}$)である．
負の再現率(Negative Recall)であれば，実際のCPUEが平均より低い地点の数($L^{-}$)を全体とした中で予測したCPUEも平均より低かった地点の数($K^{-}$)の割合($K^{-}/L^{-}$)である．

\if0
式\ref{eq:3-201}で表す階段関数f(x)と符号関数sgn，学習データのCPUEの平均値を$AVE$，i番目のテストデータを予測した時のCPUEを$PredictedCPUE_{i}$，i番目のテストデータの実際のCPUEを$CPUE_{i}(1 \leq i \leq n)$として数式で表すと次式のようになる．

\begin{eqnarray}
\label{eq:3-201}
f(x) = \left\{
\begin{array}{ll}
1 & (0 < x)\\
0 & (x \leq 0)\\
\end{array}
\right.
\end{eqnarray}

\begin{eqnarray}
\label{eq:3-200}
Accuracy = \frac{\sum_{i=1}^{n}f(sgn((AVE-PredictedCPUE_{i})(AVE-CPUE_{i})))}{n}
\end{eqnarray}

\section{適合率}
本研究の実験では考察をするために適合率も求める．
適合率(Precision)とは，一方の予測をした時にそれが正しい割合である．
正の適合率(Positive Precision)であれば，CPUEが平均より多いと予測した地点の数を全体とした時の，実際のCPUEも多かった地点の数の割合である．
負の適合率(Negative Precision)はちょうどその逆で，CPUEが平均より少ないと予測した地点の数を全体とした時の，実際のCPUEも少なかった地点の数の割合である．
数式で表すとそれぞれ次式となる．

\begin{eqnarray}
Precision^{+}  = \nonumber \\
 \frac{\sum_{i=1}^{n}f(sgn(f(PredictedCPUE_{i}-AVE)(CPUE_{i}-AVE)))}{\sum_{i=1}^{n}f(sgn(PredictedCPUE_{i}-AVE))}
\end{eqnarray}

\begin{eqnarray}
Precision^{-}  = \nonumber \\
 \frac{\sum_{i=1}^{n}f(sgn(f(AVE - PredictedCPUE_{i})(CPUE_{i}-AVE)))}{\sum_{i=1}^{n}f(sgn(AVE - PredictedCPUE_{i}))}
\end{eqnarray}
\fi

\section{HSIモデル構築}
これまでSIモデルの構築手法について説明した．
このSIモデル構築手法を各海洋環境変数ごとに適用することで，対象魚種にとって生息しやすい各海洋環境変数がわかる．
それらを統合することで多変数の漁獲予測モデルであるHSIモデルを構築する．
本研究で漁場予測の対象とするアカイカについては過去にいくつか漁場予測を試みた研究がある．
それらの研究では各SIモデルの相乗平均をHSIモデルとしている\cite{a7} \cite{related3}．
本研究ではそれを踏襲し，各SIモデルの相乗平均をHSIモデルとした（式\ref{eq:3-4}）．
\if0
SIからHSIモデルを求める方法はいくつかある
その中で過去の研究ではなぜ相乗平均だったのか書く
\fi

\begin{eqnarray}
HSI = \sqrt{ \prod SI} = \sqrt{ \prod \sum_{k=0}^{depth} a_k x_k } 
\label{eq:3-4}
\end{eqnarray}

\section{別のHSIモデル構築手法}
これまで説明したような，SIモデルを統合することでHSIモデルを構築する手法は過去の関連研究\cite{a7}\cite{related5}で行われてきた手法である．
一方でSIモデルを構築することなく，HSIモデルを直接構築する手法もありえる．
つまり式\ref{eq:3-5}は単一の海洋環境変数の総和でSIモデルを構築しているが，これを拡張して次式を考える．

\begin{eqnarray}
\label{eq:3-100}
HSI = \sum_{k=0}^{var}\sum_{j=0}^{days}\sum_{i=0}^{depth} a_{ijk} x_{ijk}
\end{eqnarray}

ただしkは塩分濃度や海水温などの海洋環境変数の種類である．

この手法が使われず，SIモデルを統合するHSIモデル構築手法が使われてきた理由の一つとして利用者の負担が軽減できるというものがある．
例えばNパターンのSIモデルが構築できる海洋環境変数をM種類使ってSIモデルを統合する場合を考える．
一つのSIモデルを構築する所要時間はNに比例するので，HSIモデル構築の所要時間はMNに比例する時間となる．
次に式\ref{eq:3-100}を使って直接HSIモデルを構築する場合を考える．
この構築手法ではSIモデルと同じようにしてHSIモデルを構築する．
とても単純にNパターンのSIモデルをM種類並べて，その中から一つを選んでHSIモデルとする場合でも，所要時間はMNに比例した時間となる．
この場合はMN時間必要であるにも関わらず，構築される関数の複雑さは先のSIモデル一つと同じ程度にしかならない．
さらに複数変数の組み合わせを考えると所要時間が爆発的に増え，人間が直接モデル構築できなくなる．
そのため従来手法ではこの構築手法は使われてこなかった．

翻って本研究ではモデル構築を全自動化している．
そのため直接HSIモデル構築を行う場合でも利用者の負担は変わらない．
以上のことから式\ref{eq:3-100}を用いてHSIモデルを構築する手法も提案する．
どちらのほうがより漁獲予測精度が良いかについては5章で実験を行う．