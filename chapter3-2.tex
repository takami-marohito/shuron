\subsection{提案手法によるSIモデル構築}
提案手法でのSIモデルの構築を説明する。
本研究で使用する海洋環境変数データは5種の変数、塩分濃度、温度、緯度方向の流速、経度方向の流速、深さ方向の流速からなる。
また各変数は特定の深さごとに値を持っており、それらの線形和を使ってSIモデル構築をする場合、次式で表すことができる。

\begin{eqnarray}
SI = \sum_{i=0}^{depth} a_i x_i
\label{eq:3-1}
\end{eqnarray}

$x_i$ は漁獲点の鉛直方向深さiでの海洋環境変数の値、$a_i$ はその係数である。
さらに過去のデータとして、先に説明した手法で計算した海洋環境変数データを用いると次式でSIモデルを表せる。

\begin{eqnarray}
SI = \sum_{j=0}^{days} \sum_{i=0}^{depth} a_{ij} x_{ij}
\label{eq:3-5}
\end{eqnarray}

$x_{ij}$ は漁獲点の鉛直方向の深さiを始点としてj日遡った地点での海洋環境変数の値、$a_{ij}$ はその係数である。

漁獲点における式(\ref{eq:3-1})のSI値を漁獲量予測に変換した値と漁獲実績(CPUE)との差の絶対値を最小化する $a_{ij}$ を求めることでSIモデルを構築できる（式\ref{eq:3-6}）。

\begin{eqnarray}
\label{eq:3-6}
& & \argmin_{a_{ij}} (|CPUE-PredictedCPUE|) \\
&=& \argmin_{a_{ij}} \left( \left| CPUE-(maxCPUE*\sum_{j=0}^{days} \sum_{i=0}^{depth} a_{ij} x_{ij} ) \right| \right)
\end{eqnarray}

また、実測した漁獲点は複数存在するのでこれを行列で表すことができる（式\ref{eq:3-7}）。

\begin{eqnarray}
\label{eq:3-7}
\argmin_{\theta} ||{\bf Y}-{\bf X}\theta||_{2}^{2}
\end{eqnarray}

{\bf Y}は$n \times 1$ 行列で、i行目はi番目の漁獲点でのCPUEとなっている。
{\bf X}はk番目の漁獲点で成立する式\ref{eq:3-5}の$x_{ij}$をk行目に横に並べた$n \times m$行列である。
$\theta$は$m \times 1$行列で、{\bf X}における海洋環境変数$x_{ij}$に対応する係数行列である。そのためmは$x_{ij}$の数と同じである。
\if0

各行列を実際に書くのもあり
X = (a_{0,0} a_{0,1} ... a_{0,59} a_{0,60} a{1,0} ... a_{54,60} )など

\fi
式\ref{eq:3-7}ではどの漁獲点でも利用可能なモデルを構築しようとしているので、$x_{ij}$はどの漁獲点でも同じ係数となる。
そのため、$\theta$は$n \times m$行列ではなく、$n \times 1$行列となる。
式\ref{eq:3-7}は機械学習の分野で教師あり学習と呼ばれたり、回帰問題と呼ばれる問題で最小二乗法などの解法によって解くことができる。
式\ref{eq:3-7}を解くと全ての変数に0でない係数が現れる。
これは全ての深さの全ての変数が漁獲量に影響するということを意味するが、例えばある深さで対象生物を漁獲する際に、同じ日の全く別の深さの海洋環境変数がその漁獲量に影響するとは考えにくく、海洋の専門家も否定している。
また、すべての変数を漁獲モデルに使用するとオーバーフィッティングの問題が発生する。
そのため、漁獲モデルに全ての変数を利用するのではなく、一部を削減する必要がある。

\section{オーバーフィッティング}
構築したモデルが、構築に使用したデータに対してはよく適合しているが、未知のデータに対して適合していない状態がオーバーフィッティング（過学習）である。
\if0
オーバーフィッティングの一般的な説明と、今回のデータでオーバーフィッティングの例を示したい
\fi
今回のように計算機による自動計算でモデルを構築する際によく問題となる状態である。
今回の例であれば、実測した漁獲点で予測させた場合は実際のCPUEに近い値が出るが、それを実際の予測に使用すると実際のCPUEとかけ離れたモデルができてしまう。
一般にオーバーフィッティングはモデルの自由度が高すぎる場合に発生する。
そこで、式\ref{eq:3-5}のように使用可能な全ての変数を使用するのではなく、変数の数を減らす工夫をする。
以下で説明する変数の数を減らすモデル構築手法はスパースモデリングとも呼ばれる。
例えば係数行列$\theta$の成分に0の項があれば、実質的に変数の数が減っていることになる。
その手法にはRidge回帰\cite{a9}、Lasso回帰\cite{a8}など様々な手法がある。
Ridge回帰は古くに提案された変数削減手法であり次のように行う。
式\ref{eq:3-7}で示した最小化式に罰則項としてL2ノルムを加えたものである。
Lpノルムは一般に$p \geq 1$で定義されるノルムで、式\ref{eq:3-8}で表せる。

\begin{eqnarray}
\label{eq:3-8}
Lp norm = ||x||_p = (|x_0|^p + |x_1|^p + |x_2|^p + ...)^{\frac{1}{p}}
\end{eqnarray}

p=2の場合がL2ノルムであり、次式で示すように各係数の二乗和の平方根となる。

\begin{eqnarray}
\label{eq:3-85}
L2norm = ||x||_2 = (|x_0|^2 + |x_1|^2 + |x_2|^2 + ...)^{\frac{1}{2}} = \sqrt{\sum_i |x_i|^2}
\end{eqnarray}

これを罰則項とした上で罰則項そのものの重み$\lambda$も考慮し、式\ref{eq:3-7}に対し適用すると次式となる。

\begin{eqnarray}
\label{eq:3-9}
\argmin_{\theta} \left( ||{\bf Y}-{\bf X}\theta||_{2}^{2} + \lambda \sqrt{\sum_i |\theta_i |^2} \right)
\end{eqnarray}

ただし、$\theta_i$は$\theta$のi番目の成分である。
式\ref{eq:3-9}がRidge回帰である。
式\ref{eq:3-9}は次のようにして解く。

式\ref{eq:3-9}は最小化を行いたいので$\theta$で偏微分すると0になる（式\ref{eq:3-9-1}）。

\begin{eqnarray}
\label{eq:3-9-1}
2 X^T X \theta - 2 X^T Y + 2 \lambda \theta = 0
\end{eqnarray}

これを整理すると、解くべき方程式は式\ref{eq:3-9-2}となる。

\begin{eqnarray}
\label{eq:3-9-2}
(X^T X + \lambda I)\theta = X^T Y
\end{eqnarray}

式\ref{eq:3-9-2}を満たす$\theta$は$X^T X + \lambda I$の逆行列を求めることで求めることができる。
これによってRidge回帰は解くことができる。

このようにして求めた解はオーバーフィッティングの問題が発生しないようなスパースなモデルになっているだろうか。
Ridge回帰では罰則項が係数の二乗和の平方根であり、変数の数（係数の非0の項の数）については一切制約がない。
しかし実際にはモデルに与える影響の小さい変数に対応する係数は0に近づき、閾値処理によって係数0にできる。
これは次の理由で説明できる。
まず、一般化したRidge回帰において、最小化式は式\ref{eq:3-10}となる。

\begin{eqnarray}
\label{eq:3-10}
min \left( E({\bf w}) + \lambda \sqrt{\sum_{i} | w_i |^{2}} \right)
\end{eqnarray}

この目的関数を$w_i$で微分すると次式になる。

\begin{eqnarray}
\label{eq:3-11}
\frac{\partial E({\bf w})}{\partial w_i} +  \lambda w_i
\end{eqnarray}

式\ref{eq:3-11}の第一項は特定の$w_i$で0になり、それ未満では正、それより大きい時は負となる。
第二項は$w_i = 0$で0になり、それ未満では負、それより大きい時は正となる。
また、線形回帰の場合第一項は階段関数となる。
そして第一項はその変数がモデルに与える影響の大小に比例する。
そのため、影響が小さい変数の場合、第二項が係数$w_i$決定に支配的となり$w_i$は0に近づく。
一方、影響の大きい変数の場合、第二項が$w_i$決定にはあまり寄与しなくなり、$w_i$はあまり0に近づかない。
モデルに対する影響の大小によって罰則項の効果が変化し、モデル決定に対して影響力の小さい変数は$w_i$が0に近づく。
しかし、この手法では$w_i$が0に近づくほど第二項の影響が小さくなるので$w_i$は完全には0にならず、閾値処理をしないと$w_i$を0にできない。

そこで、Lasso回帰が考案された。
Lasso回帰は罰則項にL1ノルムを用いた手法である。

\begin{eqnarray}
\label{eq:3-12}
L1norm = ||x||_1 = (|x_0|^1 + |x_1|^1 + |x_2|^1 + ...)^{\frac{1}{1}} = \sum_i |x_i|
\end{eqnarray}

L1ノルムとはつまり、係数行列の絶対値の和である。
こちらも変数の数（係数の非0の項の数）についての制約はない。
しかし、実際には係数の一部が0になる。
それを以下で説明する。

一般化したLasso回帰の最小化式は次式となる。

\begin{eqnarray}
\label{eq:3-13}
min E({\bf w}) + \lambda \sum_{i} | w_i |
\end{eqnarray}

式\ref{eq:3-13}はRidge回帰の時と違い単に偏微分の逆行列では解が出ない。
Lasso回帰を解くアルゴリズムはLARS\cite{a21}やGPS\cite{a22}、CDA\cite{a23}などが存在する。

\if0
分量が足りなければこれらのアルゴリズムの説明
\fi
式\ref{eq:3-13}を式\ref{eq:3-11}と同じように$w_i$で微分すると次式になる。

\begin{eqnarray}
\label{eq:3-14}
\frac{\partial E({\bf w})}{\partial w_i} + \lambda \cdot sgn(w_i)
\end{eqnarray}

sgn(x)は符号関数である。
これも先と同様に考えると$w_i$は第二項を入れない場合と比較し、0に近づく。
しかし、符号関数は$w_i$の正負のみで$w_i$の大小に関わらない値を持つ。
そのため第一項が小さく、モデルに対する影響の小さい変数は$w_i = 0$に収束する。
これにより、Ridge回帰のような閾値処理を用いることなく、係数が0となり変数の削減が可能である。

Lasso回帰は影響の小さい変数の係数が0に収束するが、あくまで罰則項は係数の絶対値の和である。
そのため、ある変数が別の変数と従属の関係にあり、モデルに与える影響が大きい場合、どちらの変数もモデルに残ってしまう。
つまり、Lasso回帰では削減できないが、モデル構築に不要な変数が存在してしまう場合がある。

そこで罰則項として、係数行列 $\theta$ のL0ノルムと重み$\lambda$ の積を加えた次式を考える。

\begin{eqnarray}
\label{eq:3-2}
\argmin_{\theta} \left( ||{\bf Y}-{\bf X}\theta||_{2}^{2} + \lambda \sum_i ||\theta_i ||_0 \right)
\end{eqnarray}

式\ref{eq:3-8}は$p\geq 1$の場合で定義されているが、それをp=0の場合にも拡張することでL0ノルムは次式で表せる。

\begin{eqnarray}
\label{eq:3-3}
L0norm = ||x||_0 = (|x_0|^0 + |x_1|^0 + |x_2|^0 + ...)^{\frac{1}{0}} = \sum_i \left( |x_i|^0 \right) ^ \infty
\end{eqnarray}

$0^0=0$ と定義した場合、$x_i = 0$のとき$0^{\infty} = 0$ 、$x_i \neq 0$のとき$1^{\infty} = 1$となる。
つまり、式(\ref{eq:3-3})は$x_i$ の非ゼロ成分の数となる。
この場合、罰則項は変数の数に比例するのでLasso回帰の場合の問題も発生しない。
また、変数の数を削減することでオーバーフィッティングの問題も発生しにくい。

本研究は以上の理由より、L0ノルムを罰則項としてモデル構築に使用する。
次に、最適化式\ref{eq:3-2}をどのようにして解くか説明する。
\if0
log (x*y*z) = logx +logy + logz
logCPUE = log(Ax1*Ax2*...) = logAx1 + logAx2 + ...
この研究だと
log(sumAx)なのでこうはならないけど、上のようにしたらどうなるか
\fi

\section{提案手法のアルゴリズム}
先に述べた計算手法を計算機上で実現するアルゴリズムについて説明する。
式\ref{eq:3-2}において、求めたい係数行列$\theta$は$n \times 1$行列で、nは海洋環境変数の数である。
一方で$\theta$を求めるために使うことができる式の数は${\bf Y}$ の行数であり、つまり漁獲点の数である。
海洋環境変数の数は$深さインデックス \times 過去のデータのサンプリング数$で、5章で行う実験では1200種類ある。
一方の漁獲点は一ヶ月分のデータで180点程しかない。
これはつまり、1200の未知数を求めたいのに対して、式が180しかないことになる。
このような連立方程式を劣決定系という。
劣決定系の線形連立方程式の解法は様々な手法があるが、本研究で扱う方程式は解がスパースであることがわかっている。

このような方程式を解く枠組みとして圧縮センシングが存在する\cite{a25}。
標本化定理では信号の最大周波数成分がW以下の時、2W以上の周波数でサンプリングすると完全に再構成可能となる。
圧縮センシングでは信号がスパースであるとすることによって標本化定理で示されるサンプリング数より少ないサンプリング数で再構成ができるようになる。
圧縮センシングの考え方は通信や測定などに応用されている。
本研究では少ないサンプリング数（実測した漁獲量）で原信号（海洋環境変数の方程式で表した漁獲量の分布）を再構成する問題なので圧縮センシングの考え方を利用できる。

本研究ではその中でもIRLS（iteratively Reweighted Least Squares）と呼ばれるアルゴリズムを利用した。
\if0
この問題のNP困難性の説明
LassoとRidgeの計算時間
\fi
\if0
この問題は劣決定系で圧縮センシングであることを説明
圧縮センシングの応用例と基本の論文
\fi

\section{IRLS}
IRLS\cite{a24}は最小二乗法を繰り返し計算することで解を得る手法である。
まず式\ref{eq:3-2}の変数を使って、行列Wを定義する。
行列Wは$m \times m$の対角行列で、mは求めようとしているSIモデルで使用する全ての海洋環境変数の数である。
そのi番目の対角成分$W_{ii} $は式\ref{eq:3-14-1}で定義する。

\begin{eqnarray}
\label{eq:3-14-1}
W_{ii} = \frac{1}{| \theta_i | + \epsilon}
\end{eqnarray}

ただし$\epsilon$は微小定数で、$\theta$の成分の内0でない任意の成分$\theta_n$に対して$\theta_n \gg \epsilon$となる定数である。
$\theta$のi番目の成分が0のときは$||W_{ii} \theta_i || = || \frac{0}{\epsilon} || = 0$となり、0でない時は$||W_{ii} \theta_i || = || \frac{\theta_i}{\theta_i} || = 1$となる。
そのため、$ ||W \theta ||^2 $はちょうどL0ノルムと同じものとなる。
式\ref{eq:3-2}はこのWを使って次のように書ける。

\begin{eqnarray}
\label{eq:3-15}
\argmin_{\theta} \left( ||{\bf Y}-{\bf X}\theta||_{2}^{2} + \lambda ||W \theta ||^2 \right) 
\end{eqnarray}

IRLS(Iteratively Reweighted Least Squares)は式\ref{eq:3-15}の$\theta$と第二項(罰則項)を交互に更新することで解に近づいていく手法である。

そのため、式\ref{eq:3-15}にステップtを導入する。
t回目の$\theta$の更新と罰則項の中のWの更新をそれぞれ$\theta^{(t)}$、$W^{(t)}$と表す。
$\theta$、Wの順に更新するものとした場合、t+1回目の$\theta$の更新は式\ref{eq:3-16}のように書ける。

\begin{eqnarray}
\label{eq:3-16}
\theta^{(t+1)} = \argmin_{\theta} \left( ||{\bf Y}-{\bf X}\theta^{(t)} ||_{2}^{2} + \lambda ||W^{(t)} \theta^{(t)} ||^2 \right) 
\end{eqnarray}

式\ref{eq:3-16}のargmin内が極値を取るとき、その$\theta$偏微分は0となる。（式\ref{eq:3-16-1}）

\begin{eqnarray}
\label{eq:3-16-1}
\frac{\partial \theta^{(t+1)}}{\partial \theta^{(t)}} = 0
\end{eqnarray}

これを満たす$\theta$が$\theta^{(t+1)}$なので\ref{eq:3-16-1}から次式が成り立つ。

\begin{eqnarray}
\label{eq:3-16-2}
X^{T}X\theta^{(t+1)} - XY + \lambda (W^{(t)})^2 \theta^{(t+1)} = 0 \\
\left( X^{T}X + \lambda (W^{(t)})^2 \right) \theta^{(t+1)} = XY \\
\theta^{(t+1)} = \left( X^{T}X + \lambda (W^{(t)})^2 \right) ^{-1} XY
\end{eqnarray}

式\ref{eq:3-16-2}のWは各成分が0または1の対角行列なので$(W)^2 = W$となり、

\begin{eqnarray}
\label{eq:3-16-3}
\theta^{(t+1)} = \left( X^{T}X + \lambda W^{(t)} \right) ^{-1} XY
\end{eqnarray}

式\ref{eq:3-16-3}を解くことで$\theta^{(t+1)}$が計算できる。
またt+1回目のWの更新は直前に更新した$\theta^{(t+1)}$を使って式\ref{eq:3-17}のように書ける。

\begin{eqnarray}
\label{eq:3-17}
W_{ii}^{(t+1)} = \frac{1}{|\theta_{i}^{(t+1)} | + \epsilon }
\end{eqnarray}

ただし、Wは対角行列で$W_{ii}$はそのi行目i列目の成分である。

ステップtを導入したWと$\theta$を使って、IRLSアルゴリズムは次のように表せる。

\begin{enumerate}
\item{t=0にする。}
\item{$\theta_{i}^0$ を全て1にする。 }
\item{$W_{ii}^{0}$ を全て1にする。}
\item{次の5-7の手順を$|| \theta^{(t+1)} - \theta^{(t)} || <tol$ となるまで繰り返す。}
\item{式\ref{eq:3-16}を解くことで$\theta^{(t+1)}$を求める。}
\item{式\ref{eq:3-17}を全てのiで解くことでWを求める。}
\item{t = t+1にする。}
\end{enumerate}

ただし、tolは微小な定数。

\if0
なぜこのアルゴリズムが変数を減らす方向に働くのか
Wの更新としーたを求める逆行列計算を繰り返してるだけなのに
→IRLSの論文の定理5.3の条件ならIRLSは収束し、その解がk-スパースとなるらしい（6章）
\fi

\section{最適な罰則項の重みの決定}
先に説明したIRLSアルゴリズムによって、L0ノルムを罰則項としたモデル構築が可能である。
一方、モデルにはまだ罰則項の重み$\lambda$が自由度として残っている。
重み$\lambda = 0$の時は罰則項のない最小二乗法となり、重みが大きすぎると$\theta={\bf 0}$が解となる。
重みの決定については次のように行う。
重みを変化させて、それぞれの重みでモデル構築をする。
その後、各モデルについて次に説明する正答率を計算し、それが最大となる重みを選択することで重みを決定する。
このようにして決定した重みを用いて構築した漁獲モデルが、その海洋環境変数のSIモデルとなる。

\section{正答率}
本研究では正答率を定義し、その大小によって罰則項の重みを決定する。
正答率は機械学習の分類器などの評価でよく使われる指標である。
モデル構築の時に使用していないデータ、つまり未知のデータを分類させた時にどれだけ正しく判断できたのかを意味する。
本研究では次のようにして正答率を求める。
まず実測したCPUEデータ全体をテストデータと学習データに分割する。
そして学習データのみでモデル構築を行う。
テストデータの漁獲点座標を構築したモデルに入力して、CPUEの予測値を求める。
また同時に学習データ内の実測値としてのCPUEの平均値を求める。
予測したCPUEと学習データの平均CPUEを比較した時の大小を求める。
次に、予測した漁獲点での実際のCPUEと学習データの平均CPUEを比較した時の大小を求める。
これらが一致するかどうかを全てのテストデータに対し求め、その率を正答率とした。
\if0
なぜ予測CPUEの距離ではなくCPUEの正答率なのか
\fi

\section{HSIモデル構築}
先程のSIモデル構築を各海洋環境変数ごとに適用することで、対象魚種にとって生息しやすい各海洋環境変数がわかる。
本研究で漁場予測の対象とするアカイカについては過去にいくつか漁場予測を試みた研究がある。
それらの研究では各SIモデルの相乗平均をHSIモデルとしている\cite{a7} \cite{related3}。
本研究ではそれを踏襲し、各SIモデルの相乗平均をHSIモデルとした（式\ref{eq:3-4}）。
\if0
SIからHSIモデルを求める方法はいくつかある
その中で過去の研究ではなぜ相乗平均だったのか書く
\fi

\begin{eqnarray}
HSI = \sqrt{ \prod SI} = \sqrt{ \prod \sum_{k=0}^{depth} a_k x_k } 
\label{eq:3-4}
\end{eqnarray}